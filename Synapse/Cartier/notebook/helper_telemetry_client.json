{
	"name": "helper_telemetry_client",
	"properties": {
		"folder": {
			"name": "helpers"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "devpoolv34",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "112g",
			"driverCores": 16,
			"executorMemory": "112g",
			"executorCores": 16,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "2aefda11-1d2a-4757-8a62-033466001523"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/f8a339ea-4445-4d69-a4bb-b7c77c9db241/resourceGroups/RG-Cartier-Dev/providers/Microsoft.Synapse/workspaces/synw-time-cartier-dev/bigDataPools/devpool",
				"name": "devpoolv34",
				"type": "Spark",
				"endpoint": "https://synw-time-cartier-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/devpool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 10,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import logging\r\n",
					"import platform\r\n",
					"import time\r\n",
					"from datetime import datetime\r\n",
					"from opencensus.ext.azure.log_exporter import AzureLogHandler\r\n",
					"from opencensus.ext.azure.common.protocol import Envelope\r\n",
					"from opencensus.ext.azure import metrics_exporter\r\n",
					"from opencensus.stats import aggregation as aggregation_module\r\n",
					"from opencensus.stats import measure as measure_module\r\n",
					"from opencensus.stats import stats as stats_module\r\n",
					"from opencensus.stats import view as view_module\r\n",
					"from opencensus.tags import tag_map as tag_map_module\r\n",
					"from typing import Optional, Dict\r\n",
					"\r\n",
					"class TelemetryClient:\r\n",
					"    \"\"\"\r\n",
					"    A client for sending telemetry data to Azure Monitor using OpenCensus.\r\n",
					"    \"\"\"\r\n",
					"    def __init__(\r\n",
					"            self, \r\n",
					"            instrumentation_key: str, \r\n",
					"            execution_id: str, \r\n",
					"            execution_type: str, \r\n",
					"            execution_time: str\r\n",
					"        ):\r\n",
					"        \"\"\"\r\n",
					"        Initialize a new TelemetryClient.\r\n",
					"\r\n",
					"        Arguments:\r\n",
					"            instrumentation_key: The instrumentation key for the Azure Monitor resource.\r\n",
					"            execution_id: The id of the exectuion which is set to the col ai.operation.parentId within the logs.\r\n",
					"            execution_type: The name of the caller which is set to the col ai.operation.name within the logs.\r\n",
					"            execution_time: The timestamp of the execution which is set to the col ai.session.id within the logs.       \r\n",
					"        \"\"\"\r\n",
					"        self.instrumentation_key = instrumentation_key\r\n",
					"        self.execution_id = execution_id\r\n",
					"        self.execution_type = execution_type\r\n",
					"        self.execution_time = \"{:%Y_%m_%d_%H_%M_%S}\".format(datetime.strptime(execution_time,\"%Y-%m-%dT%H:%M:%S.%fZ\"))\r\n",
					"        self.stats = stats_module.stats\r\n",
					"        self.view_manager = self.stats.view_manager\r\n",
					"        self.stats_recorder = self.stats.stats_recorder\r\n",
					"        self.logger = self._configure_logging()\r\n",
					"        self._configure_exporter()\r\n",
					"\r\n",
					"    def _configure_logging(self) -> logging.Logger:\r\n",
					"        \"\"\"\r\n",
					"        Configure the logging system to use the AzureLogHandler from OpenCensus.\r\n",
					"\r\n",
					"        Returns:\r\n",
					"            A logger instance.\r\n",
					"        \"\"\"    \r\n",
					"        logger = logging.getLogger(__name__)\r\n",
					"        logger.setLevel(logging.DEBUG)\r\n",
					"\r\n",
					"        telemetry_handler = AzureLogHandler(connection_string=f'InstrumentationKey={self.instrumentation_key}')\r\n",
					"\r\n",
					"        def add_extra_data(envelope: Envelope) -> bool:\r\n",
					"            envelope.tags['ai.operation.parentId'] = self.execution_id \r\n",
					"            envelope.tags['ai.operation.name'] = self.execution_type\r\n",
					"            envelope.tags['ai.session.id'] = self.execution_time\r\n",
					"            \r\n",
					"            return True\r\n",
					"\r\n",
					"        telemetry_handler.add_telemetry_processor(add_extra_data)\r\n",
					"        telemetry_handler.setLevel(logging.INFO)\r\n",
					"\r\n",
					"        logger.addHandler(telemetry_handler)\r\n",
					"        return logger\r\n",
					"\r\n",
					"    def _configure_exporter(self):\r\n",
					"        \"\"\"\r\n",
					"        Configures the application insights instance to the metric view_manager class.\r\n",
					"        \"\"\"            \r\n",
					"        exporter = metrics_exporter.new_metrics_exporter(connection_string=f'InstrumentationKey={self.instrumentation_key}')\r\n",
					"        self.view_manager.register_exporter(exporter)\r\n",
					"\r\n",
					"    def track_event(self, name: str, properties: dict = None) -> None:\r\n",
					"        \"\"\"\r\n",
					"        Track an event with the given name and properties.\r\n",
					"\r\n",
					"        Arguments:\r\n",
					"            name: The name of the event to track.\r\n",
					"            properties: Additional properties to include with the event (optional).\r\n",
					"        \"\"\"    \r\n",
					"        self.logger.info(\r\n",
					"            name,\r\n",
					"            extra = {'custom_dimensions': properties or {}, 'ai.operation.name': 'track_event' }\r\n",
					"        )\r\n",
					"\r\n",
					"    def track_exception(self, ex: Exception, properties: dict = None) -> None:\r\n",
					"        \"\"\"\r\n",
					"        Track an exception with the given properties.\r\n",
					"\r\n",
					"        Arguments:\r\n",
					"            ex: The exception to track.\r\n",
					"            properties: Additional properties to include with the exception (optional).\r\n",
					"        \"\"\"    \r\n",
					"        self.logger.exception(\r\n",
					"            ex,\r\n",
					"            extra = {'custom_dimensions': properties or {}, 'ai.operation.name': 'track_exception'}\r\n",
					"        )\r\n",
					"\r\n",
					"    def track_metric(self, metric_name: str, value: int) -> None:\r\n",
					"        \"\"\"\r\n",
					"        Track a metric with the given name, value.\r\n",
					"\r\n",
					"        Arguments:\r\n",
					"            metric_name (str): The name of the metric to track.\r\n",
					"            value (int): The numeric value of the metric to track.\r\n",
					"        \"\"\"\r\n",
					"        metric_description = f\"SumAggregation of {metric_name} on a 60 second interval.\"\r\n",
					"        metric_measure = measure_module.MeasureInt(metric_name, metric_description, metric_name)\r\n",
					"\r\n",
					"        metric_view = view_module.View(metric_name, metric_description, [], metric_measure, aggregation_module.SumAggregation())\r\n",
					"        self.view_manager.register_view(metric_view)\r\n",
					"\r\n",
					"        measurement_map = self.stats_recorder.new_measurement_map()\r\n",
					"        tag_map = tag_map_module.TagMap()\r\n",
					"\r\n",
					"        measurement_map.measure_int_put(metric_measure, value)\r\n",
					"        measurement_map.record(tag_map)\r\n",
					"\r\n",
					"    def track_trace(self, name: str, properties: dict = None) -> None:\r\n",
					"        \"\"\"\r\n",
					"        Track a trace with the given name and properties.\r\n",
					"\r\n",
					"        Args:\r\n",
					"            name: The name of the trace to track.\r\n",
					"            properties: Additional properties to include with the trace (optional).\r\n",
					"        \"\"\"    \r\n",
					"        self.logger.info(\r\n",
					"            'Trace: %s',\r\n",
					"            name,\r\n",
					"            extra = {'custom_dimensions': properties or {}, 'ai.operation.name': 'track_trace'}\r\n",
					"        )\r\n",
					"\r\n",
					"    def flush(self) -> None:\r\n",
					"        \"\"\"\r\n",
					"        Flush any telemetry data that has not yet been sent.\r\n",
					"        \"\"\" \r\n",
					"        for handler in self.logger.handlers:\r\n",
					"            if isinstance(handler, AzureLogHandler):\r\n",
					"                handler.flush()\r\n",
					""
				],
				"execution_count": 8
			}
		]
	}
}