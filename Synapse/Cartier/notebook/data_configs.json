{
	"name": "data_configs",
	"properties": {
		"folder": {
			"name": "config"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "devpoolv34",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "112g",
			"driverCores": 16,
			"executorMemory": "112g",
			"executorCores": 16,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "c195e6ec-cd88-41df-a162-6da8f204a8af"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/f8a339ea-4445-4d69-a4bb-b7c77c9db241/resourceGroups/RG-Cartier-Dev/providers/Microsoft.Synapse/workspaces/synw-time-cartier-dev/bigDataPools/devpool",
				"name": "devpoolv34",
				"type": "Spark",
				"endpoint": "https://synw-time-cartier-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/devpool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 10,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**Functional config class per dataset**\r\n",
					"- configs contain dataset metadata that is used by notebooks\r\n",
					"- each dataset needs a config value to be processed\r\n",
					"- examples of metadata include: schema, validations, primarKeys etc\r\n",
					"- **a newly added config must have unit tests validating config value**"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"class DataConfigs:\r\n",
					"\r\n",
					"    shift_config =  '''{\r\n",
					"        \"dataName\": \"shift\",\r\n",
					"        \"dataType\": \"api\",\r\n",
					"        \"dataSource\": \"wfs\",\r\n",
					"        \"version\": 1,\r\n",
					"        \"primaryKeyExpr\": \"CASE WHEN dataChange = 'DELETE' THEN CONCAT_WS('_', externalMatchId, workDate) ELSE CONCAT_WS('_', externalMatchId, workDate) END\", \r\n",
					"        \"bronze\": {\r\n",
					"            \"finalizedSchemaMapping\": {\r\n",
					"            },\r\n",
					"            \"validationColumnRules\": { \r\n",
					"                \"columnIsNotNull\": {\r\n",
					"                    \"targetColumns\": [\"dataChange\", \"externalMatchId\", \"workDate\", \"recordId\", \"cursor\", \"ingestionTime\",\"bronze_index\"],\r\n",
					"                    \"ruleExpression\": \"column_name IS NOT NULL\",\r\n",
					"                    \"ruleExpressionType\": \"PySpark.DataFrame.Filter(str)\"\r\n",
					"                }\r\n",
					"            },\r\n",
					"            \"validationDataframeRules\": {\r\n",
					"                \"initialSchema\": {\r\n",
					"                    \"externalMatchId\": \"StringType()\", \r\n",
					"                    \"dataChange\": \"StringType()\",\r\n",
					"                    \"workDate\": \"StringType()\",\r\n",
					"                    \"recordId\": \"StringType()\"\r\n",
					"                }                 \r\n",
					"            }\r\n",
					"        },\r\n",
					"        \"silver\": {\r\n",
					"            \"finalizedSchemaMapping\": {\r\n",
					"                \"externalMatchId\" : \"externalMatchId\", \r\n",
					"                \"shifts_shiftId\" : \"shifts_shiftId\", \r\n",
					"                \"workDate\" : \"workDate\",\r\n",
					"                \"shifts_endAt\" : \"shifts_endAt\" ,\r\n",
					"                \"shifts_startAt\" : \"shifts_startAt\",\r\n",
					"                \"shifts_activities_activityId\" : \"shifts_activities_activityId\",\r\n",
					"                \"shifts_activities_startAt\" : \"shifts_activities_startAt\",\r\n",
					"                \"shifts_activities_endAt\" : \"shifts_activities_endAt\",\r\n",
					"                \"shifts_activities_task\" : \"shifts_activities_task\",\r\n",
					"                \"bronze_index\": \"bronze_index\",\r\n",
					"                \"gold_index\": \"gold_index\",\r\n",
					"                \"isDeleted\": \"isDeleted\",\r\n",
					"                \"dataChange\": \"dataChange\",\r\n",
					"                \"recordId\": \"recordId\"\r\n",
					"            },\r\n",
					"            \"validationColumnRules\": { \r\n",
					"                \"columnIsNotNull\": {\r\n",
					"                    \"targetColumns\": [\"dataChange\", \"externalMatchId\", \"bronze_index\", \"workDate\", \"recordId\"],\r\n",
					"                    \"ruleExpression\": \"column_name IS NOT NULL\",\r\n",
					"                    \"ruleExpressionType\": \"PySpark.DataFrame.Filter(str)\"\r\n",
					"                }\r\n",
					"            },\r\n",
					"            \"validationDataframeRules\": {\r\n",
					"                \"initialSchema\": {\r\n",
					"                    \"externalMatchId\": \"StringType()\",\r\n",
					"                    \"bronze_index\": \"IntegerType()\",\r\n",
					"                    \"workDate\": \"StringType()\",\r\n",
					"                    \"dataChange\": \"StringType()\",\r\n",
					"                    \"recordId\": \"StringType()\"\r\n",
					"                }                                    \r\n",
					"            },  \r\n",
					"            \"scientificNotationConversionExpr\": \"CASE WHEN timeRecords_hours RLIKE '[Ee]' THEN (FORMAT_NUMBER(CAST(timeRecords_hours AS DOUBLE), 5)) ELSE timeRecords_hours END\"\r\n",
					"        },\r\n",
					"        \"gold\": {\r\n",
					"            \"finalizedSchemaMapping\": {\r\n",
					"                \"ID\": \"gold_index\",\r\n",
					"                \"PersonnelNumber\" : \"externalMatchId\" ,\r\n",
					"                \"EffectiveDate\" : \"workDate\",\r\n",
					"                \"ShiftId\" : \"shifts_shiftId\", \r\n",
					"                \"ShiftStartAt\" : \"shifts_startAt\",\r\n",
					"                \"ShiftEndAt\" : \"shifts_endAt\",\r\n",
					"                \"ActivityId\": \"shifts_activities_activityId\",\r\n",
					"                \"ActivityStartAt\" : \"shifts_activities_startAt\",\r\n",
					"                \"ActivityEndAt\": \"shifts_activities_endAt\",\r\n",
					"                \"Task\": \"shifts_activities_task\",\r\n",
					"                \"IsDeleted\": \"isDeleted\"\r\n",
					"            },\r\n",
					"            \"validationColumnRules\": { \r\n",
					"                \"columnIsNotNull\": {\r\n",
					"                    \"targetColumns\": [\"externalMatchId\", \"workDate\", \"gold_index\"],\r\n",
					"                    \"ruleExpression\": \"column_name IS NOT NULL\",\r\n",
					"                    \"ruleExpressionType\": \"PySpark.DataFrame.Filter(str)\"\r\n",
					"                }\r\n",
					"            },\r\n",
					"            \"validationDataframeRules\": {\r\n",
					"                \"initialSchema\": {\r\n",
					"                    \"externalMatchId\": \"StringType()\",\r\n",
					"                    \"workDate\": \"StringType()\",\r\n",
					"                    \"gold_index\": \"IntegerType()\"\r\n",
					"                }                                    \r\n",
					"            }    \r\n",
					"        }\r\n",
					"    }'''\r\n",
					"    \r\n",
					"    calculated_time_config =  '''{\r\n",
					"        \"dataName\": \"calculated-time\",\r\n",
					"        \"dataType\": \"api\",\r\n",
					"        \"dataSource\": \"wfs\",\r\n",
					"        \"version\": 1,\r\n",
					"        \"primaryKeyExpr\": \"CASE WHEN dataChange = 'DELETE' THEN CONCAT_WS('_', externalMatchId, workDate) ELSE CONCAT_WS('_', externalMatchId, timeRecords_workDate) END\", \r\n",
					"        \"bronze\": {\r\n",
					"            \"finalizedSchemaMapping\": {\r\n",
					"            },\r\n",
					"            \"validationColumnRules\": { \r\n",
					"                \"columnIsNotNull\": {\r\n",
					"                    \"targetColumns\": [\"dataChange\", \"externalMatchId\", \"workDate\", \"recordId\", \"cursor\", \"ingestionTime\",\"bronze_index\"],\r\n",
					"                    \"ruleExpression\": \"column_name IS NOT NULL\",\r\n",
					"                    \"ruleExpressionType\": \"PySpark.DataFrame.Filter(str)\"\r\n",
					"                }\r\n",
					"            },\r\n",
					"            \"validationDataframeRules\": {\r\n",
					"                \"initialSchema\": {\r\n",
					"                    \"externalMatchId\": \"StringType()\", \r\n",
					"                    \"dataChange\": \"StringType()\",\r\n",
					"                    \"workDate\": \"StringType()\",\r\n",
					"                    \"recordId\": \"StringType()\"\r\n",
					"                }                 \r\n",
					"            }\r\n",
					"        },\r\n",
					"        \"silver\": {\r\n",
					"            \"finalizedSchemaMapping\": {\r\n",
					"                \"bronze_index\": \"bronze_index\",\r\n",
					"                \"externalMatchId\" : \"externalMatchId\",\r\n",
					"                \"workDate\" : \"workDate\",\r\n",
					"                \"timeRecords_startTimestamp\" : \"timeRecords_startTimestamp\",\r\n",
					"                \"timeRecords_endTimestamp\" : \"timeRecords_endTimestamp\",\r\n",
					"                \"timeRecords_payCode\" : \"timeRecords_payCode\",\r\n",
					"                \"timeRecords_hours\" : \"timeRecords_hours\",\r\n",
					"                \"timeRecords_grossPay\" : \"timeRecords_grossPay\",\r\n",
					"                \"timeRecords_additionalFields_DAYS_OFF\" : \"timeRecords_additionalFields_DAYS_OFF\",\r\n",
					"                \"status\" : \"status\",\r\n",
					"                \"value\" : \"Value\",\r\n",
					"                \"unit\" : \"Unit\",\r\n",
					"                \"timeRecords_workDate\" : \"timeRecords_workDate\",\r\n",
					"                \"timeRecords_additionalFields_SP_EARNINGS_CODE\" : \"timeRecords_additionalFields_SP_EARNINGS_CODE\",\r\n",
					"                \"gold_index\": \"gold_index\",\r\n",
					"                \"isDeleted\": \"isDeleted\",\r\n",
					"                \"dataChange\": \"dataChange\",\r\n",
					"                \"recordId\": \"recordId\"\r\n",
					"            },\r\n",
					"            \"transformations\":{\r\n",
					"                \"transformExprABS\": \"CASE WHEN timeRecords_additionalFields_SP_EARNINGS_CODE = 'ABS' THEN 1 ELSE 0 END = 1\",\r\n",
					"                \"transformExprATT\": \"CASE WHEN timeRecords_additionalFields_SP_EARNINGS_CODE = 'ATT' THEN 1 ELSE 0 END = 1\"\r\n",
					"            },\r\n",
					"\r\n",
					"            \"validationColumnRules\": {        \r\n",
					"                \"columnIsNotNull\": {\r\n",
					"                    \"targetColumns\": [\"dataChange\", \"externalMatchId\", \"bronze_index\", \"workDate\", \"recordId\"],\r\n",
					"                    \"ruleExpression\": \"column_name IS NOT NULL\",\r\n",
					"                    \"ruleExpressionType\": \"PySpark.DataFrame.Filter(str)\"\r\n",
					"                }                     \r\n",
					"            },\r\n",
					"            \"validationDataframeRules\": {     \r\n",
					"                \"initialSchema\": {\r\n",
					"                    \"dataChange\": \"StringType()\",\r\n",
					"                    \"externalMatchId\": \"StringType()\",\r\n",
					"                    \"bronze_index\": \"IntegerType()\",\r\n",
					"                    \"workDate\": \"StringType()\",\r\n",
					"                    \"recordId\": \"StringType()\"\r\n",
					"                }                            \r\n",
					"            }, \r\n",
					"            \"scientificNotationConversionExpr\": \"CASE WHEN timeRecords_hours RLIKE '[Ee]' THEN (FORMAT_NUMBER(CAST(timeRecords_hours AS DOUBLE), 5)) ELSE timeRecords_hours END\"\r\n",
					"        },\r\n",
					"        \"gold\": {\r\n",
					"            \"finalizedSchemaMapping\": {\r\n",
					"                \"ID\": \"gold_index\",\r\n",
					"                \"PersonnelNumber\" : \"externalMatchId\",\r\n",
					"                \"EffectiveDate\" : \"workDate\",\r\n",
					"                \"PayCode\": \"timeRecords_payCode\",\r\n",
					"                \"StartTime\" : \"timeRecords_startTimestamp\",\r\n",
					"                \"EndTime\" : \"timeRecords_endTimestamp\",\r\n",
					"                \"Value\" : \"value\",\r\n",
					"                \"Unit\" : \"unit\",\r\n",
					"                \"Status\":\"status\",\r\n",
					"                \"IsDeleted\": \"isDeleted\"\r\n",
					"                \r\n",
					"            },\r\n",
					"            \"validationColumnRules\": { \r\n",
					"                \"columnIsNotNull\": {\r\n",
					"                    \"targetColumns\": [\"externalMatchId\", \"workDate\", \"gold_index\"],\r\n",
					"                    \"ruleExpression\": \"column_name IS NOT NULL\",\r\n",
					"                    \"ruleExpressionType\": \"PySpark.DataFrame.Filter(str)\"\r\n",
					"                }\r\n",
					"            },\r\n",
					"            \"validationDataframeRules\": {\r\n",
					"                \"initialSchema\": {\r\n",
					"                    \"externalMatchId\": \"StringType()\",\r\n",
					"                    \"workDate\": \"StringType()\"\r\n",
					"                }                                    \r\n",
					"            }    \r\n",
					"        }\r\n",
					"    }'''\r\n",
					""
				],
				"execution_count": 3
			}
		]
	}
}