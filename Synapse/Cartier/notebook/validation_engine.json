{
	"name": "validation_engine",
	"properties": {
		"folder": {
			"name": "validation"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "devpoolv34",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "112g",
			"driverCores": 16,
			"executorMemory": "112g",
			"executorCores": 16,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "394aaab4-15d2-4066-bb88-01469e8ff2ab"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/f8a339ea-4445-4d69-a4bb-b7c77c9db241/resourceGroups/RG-Cartier-Dev/providers/Microsoft.Synapse/workspaces/synw-time-cartier-dev/bigDataPools/devpool",
				"name": "devpoolv34",
				"type": "Spark",
				"endpoint": "https://synw-time-cartier-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/devpool",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 10,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql import DataFrame\r\n",
					"from typing import List, Dict, Any\r\n",
					"from datetime import datetime\r\n",
					"\r\n",
					"class ValidationEngine:\r\n",
					"    \"\"\"Class supporting validations on dataframes\"\"\"\r\n",
					"    def __init__(\r\n",
					"        self, \r\n",
					"        telemetry_client: TelemetryClient,\r\n",
					"        params: Dict[str, Any],\r\n",
					"        datalake_client: DataLakeClient,\r\n",
					"    ):\r\n",
					"        self.telemetry_client = telemetry_client\r\n",
					"        self.datalake_client = datalake_client\r\n",
					"        self.data_type = params.get(\"api_name\") or params.get(\"data_type\")\r\n",
					"        self.run_execution_time = \"{:%Y_%m_%d_%H_%M_%S}\".format(datetime.strptime(params.get(\"run_execution_time\"),\"%Y-%m-%dT%H:%M:%S.%fZ\"))\r\n",
					"\r\n",
					"    def validate_df_columns(self, validation_df: DataFrame, validation_column_rules: dict) -> DataFrame: \r\n",
					"        \"\"\"\r\n",
					"        Performs a set of column validations on the given dataframe rows\r\n",
					"        Creates parquet with invalid records, logs error with location & removes failed rows from dataframe\r\n",
					"        Does not throw error, only logs error, as failures can be scoped to a singular row\r\n",
					"\r\n",
					"            Parameters:\r\n",
					"            validation_df (dataframe): df to validate\r\n",
					"            validation_column_rules (object): an object containg the validations to perform\r\n",
					"\r\n",
					"            Returns:\r\n",
					"            filtered dataframe with rows which passed validation\r\n",
					"        \"\"\"        \r\n",
					"        passed_df = validation_df\r\n",
					"        for rule_name, rule_values in validation_column_rules.items():\r\n",
					"\r\n",
					"            passed_df = self.__column_rule_processor(passed_df, rule_name, rule_values[\"ruleExpression\"], rule_values[\"targetColumns\"])\r\n",
					"\r\n",
					"        return passed_df\r\n",
					"\r\n",
					"    def validate_df_schema(self, validation_df: DataFrame, expected_columns_schema: dict):\r\n",
					"        \"\"\"\r\n",
					"        Performs a schema validation on given dataframe\r\n",
					"        Throws exception if schema validations fails as this is considered a terminal error\r\n",
					"\r\n",
					"            Parameters:\r\n",
					"            validation_df (DataFrame): df to validate\r\n",
					"            expected_columns_schema (dict): a dictionary containg the epexted columns & types\r\n",
					"        \"\"\"\r\n",
					"        try:\r\n",
					"            validation_df_columns = set(validation_df.schema.names)\r\n",
					"            expected_column_keys = set(expected_columns_schema.keys())\r\n",
					"            \r\n",
					"            if expected_column_keys.issubset(validation_df_columns):\r\n",
					"                \r\n",
					"                for expected_column_name, expected_column_type in expected_columns_schema.items():\r\n",
					"                    actual_type = validation_df.schema[expected_column_name].dataType\r\n",
					"\r\n",
					"                    if str(actual_type) != expected_column_type:\r\n",
					"                        raise TypeError(f\"ValidationEngine error for {self.data_type} on {self.run_execution_time}: The DataFrame schema has invalid column type for {expected_column_name}.\\n \\\r\n",
					"                        Expected type: {expected_column_type}.\\n \\\r\n",
					"                        Actual type: {actual_type}.\")\r\n",
					"            else:\r\n",
					"                raise TypeError(f\"ValidationEngine error for {self.data_type} on {self.run_execution_time}: The DataFrame schema does not contain all required columns.\\n \\\r\n",
					"                Expected columns: {expected_column_keys}\\n \\\r\n",
					"                Actual columns: {validation_df_columns}\")\r\n",
					"        except Exception as e:\r\n",
					"            raise e        \r\n",
					"\r\n",
					"    def __column_rule_processor(\r\n",
					"        self, \r\n",
					"        validation_df: DataFrame, \r\n",
					"        rule_name: str, \r\n",
					"        rule_expression: str, \r\n",
					"        target_columns: List[str]\r\n",
					"    ) -> DataFrame:                \r\n",
					"        \"\"\"\r\n",
					"        Performs validations on column values for given dataframe\r\n",
					"        Filters out invalid rows that do not meet validations\r\n",
					"\r\n",
					"            Parameters:\r\n",
					"            validation_df (dataframe): df to validate\r\n",
					"            rule_name (string): name of the validation rule\r\n",
					"            rule_expression (string): a sql expression to filter columns 'column_name IS NOT NULL'\r\n",
					"            target_columns (string): a list of columns to validate '[\"dataChange\", \"externalMatchId\"]'\r\n",
					"\r\n",
					"            Returns:\r\n",
					"            filtered dataframe with records which passed validation\r\n",
					"        \"\"\"\r\n",
					"        column_name = \"column_name\"\r\n",
					"        passed_df = validation_df\r\n",
					"        \r\n",
					"        for target_column in target_columns:            \r\n",
					"            col_rule_expression = rule_expression.replace(column_name, target_column)\r\n",
					"            passed_df = passed_df.filter(col_rule_expression)\r\n",
					"        \r\n",
					"        failed_df = validation_df.subtract(passed_df)\r\n",
					"        failed_count = failed_df.count()     \r\n",
					"        \r\n",
					"        if failed_count > 0:\r\n",
					"            \r\n",
					"            failed_validations_location = f\"errors/validations/{self.data_type}/{rule_name}/{self.run_execution_time}\"\r\n",
					"        \t\r\n",
					"            self.datalake_client.write_parquet(failed_df, failed_validations_location)\r\n",
					"            \r\n",
					"            self.telemetry_client.track_exception(f\"ValidationEngine error for {self.data_type} on {self.run_execution_time}: detected {failed_count} failed {rule_name} on columns {target_columns}. Review parquet: {failed_validations_location}.\")\r\n",
					"            self.telemetry_client.track_metric(f\"Error_{rule_name}_{self.data_type}\", failed_count)\r\n",
					"        \r\n",
					"        return passed_df    \r\n",
					"\r\n",
					"\r\n",
					"    def existing_full_count_has_not_dropped(\r\n",
					"        self, \r\n",
					"        deviation_percentage: int, \r\n",
					"        existing_full_df_count: int, \r\n",
					"        new_full_df_count: int, \r\n",
					"        data_type_code=\"\"\r\n",
					"    ):\r\n",
					"        \"\"\"\r\n",
					"        Performs a count check on provided full dataframes.\r\n",
					"        Logs exception when existing count is 0; should only happen during initial run, else error.\r\n",
					"        Raises exception if count of processed_full_df is less than count of existing_full_df.\r\n",
					"        Count of processed should never be less than existing given only soft-deletes and updates/merges are performed.\r\n",
					"\r\n",
					"            Parameters:\r\n",
					"            deviation_percentage (float): deviation percentage\r\n",
					"            new_full_df_count (int): count of new dataframe records\r\n",
					"            existing_full_df_count (int): count of existing dataframe records\r\n",
					"            data_type_code (optional string): data type code of wfs api type \r\n",
					"        \"\"\"\r\n",
					"        if (existing_full_df_count == 0):\r\n",
					"          self.telemetry_client.track_exception(f\"Existing gold parquet for {self.data_type} {data_type_code} has record count of 0. This should only happen during initial run; if not initial run this is a valid error.\")\r\n",
					"        else:\r\n",
					"            percentage_difference = ((new_full_df_count - existing_full_df_count) / existing_full_df_count) * 100\r\n",
					"            \r\n",
					"            if percentage_difference < deviation_percentage:\r\n",
					"                raise ValueError(f\"ValidationEngine error for {self.data_type} {data_type_code} on {self.run_execution_time}: \\n \\\r\n",
					"                Count of new full df should never be less than count of existing full df. \\n \\\r\n",
					"                This behavior means rows got deleted during processing of transformation data. \\n \\\r\n",
					"                Detected a deviation of {percentage_difference} which should not be below {deviation_percentage} threshold. \\n \\\r\n",
					"                Existing count: {existing_full_df_count}. Processed count: {new_full_df_count}.\")\r\n",
					"        "
				],
				"execution_count": null
			}
		]
	}
}